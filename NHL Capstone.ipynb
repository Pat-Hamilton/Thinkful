{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.ticker as mtick\n",
    "import copy\n",
    "# from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "import keras\n",
    "from tensorflow.python.keras import layers as layer_module\n",
    "from tensorflow.python.keras.engine import base_layer\n",
    "from tensorflow.python.keras.engine import base_layer_utils\n",
    "from tensorflow.python.keras.engine import input_layer\n",
    "from tensorflow.python.keras.engine import training\n",
    "from tensorflow.python.keras.engine import training_utils\n",
    "from tensorflow.python.keras.saving.saved_model import model_serialization\n",
    "from tensorflow.python.keras.utils import layer_utils\n",
    "from tensorflow.python.keras.utils import tf_utils\n",
    "from tensorflow.python.platform import tf_logging as logging\n",
    "from tensorflow.python.training.tracking import base as trackable\n",
    "from tensorflow.python.util import nest\n",
    "from tensorflow.python.util import tf_inspect\n",
    "from tensorflow.python.util.tf_export import keras_export\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nat\n",
      "Ht\n",
      "Wt\n",
      "DftYr\n",
      "DftRd\n",
      "Ovrl\n",
      "Hand\n",
      "Position\n",
      "GP\n",
      "G\n",
      "A\n",
      "A1\n",
      "A2\n",
      "PTS\n",
      "+/-\n",
      "E+/-\n",
      "PIM\n",
      "Shifts\n",
      "TOI\n",
      "TOIX\n",
      "TOI/GP\n",
      "TOI/GP.1\n",
      "TOI%\n",
      "IPP%\n",
      "SH%\n",
      "SV%\n",
      "PDO\n",
      "F/60\n",
      "A/60\n",
      "Pct%\n",
      "Diff\n",
      "Diff/60\n",
      "iCF\n",
      "iCF.1\n",
      "iFF\n",
      "iSF\n",
      "iSF.1\n",
      "iSF.2\n",
      "ixG\n",
      "iSCF\n",
      "iRB\n",
      "iRS\n",
      "iDS\n",
      "sDist\n",
      "Pass\n",
      "iHF\n",
      "iHF.1\n",
      "iHA\n",
      "iHDf\n",
      "iMiss\n",
      "iGVA\n",
      "iTKA\n",
      "iBLK\n",
      "iGVA.1\n",
      "iTKA.1\n",
      "iBLK.1\n",
      "BLK%\n",
      "iFOW\n",
      "iFOL\n",
      "iFOW.1\n",
      "iFOL.1\n",
      "FO%\n",
      "%FOT\n",
      "dzFOW\n",
      "dzFOL\n",
      "nzFOW\n",
      "nzFOL\n",
      "ozFOW\n",
      "ozFOL\n",
      "FOW.Up\n",
      "FOL.Up\n",
      "FOW.Down\n",
      "FOL.Down\n",
      "FOW.Close\n",
      "FOL.Close\n",
      "OTG\n",
      "1G\n",
      "GWG\n",
      "ENG\n",
      "PSG\n",
      "PSA\n",
      "G.Bkhd\n",
      "G.Dflct\n",
      "G.Slap\n",
      "G.Snap\n",
      "G.Tip\n",
      "G.Wrap\n",
      "G.Wrst\n",
      "CBar \n",
      "Post\n",
      "Over\n",
      "Wide\n",
      "S.Bkhd\n",
      "S.Dflct\n",
      "S.Slap\n",
      "S.Snap\n",
      "S.Tip\n",
      "S.Wrap\n",
      "S.Wrst\n",
      "iPenT\n",
      "iPenD\n",
      "iPENT\n",
      "iPEND\n",
      "iPenDf\n",
      "NPD\n",
      "Min\n",
      "Maj\n",
      "Match\n",
      "Misc\n",
      "Game\n",
      "CF\n",
      "CA\n",
      "FF\n",
      "FA\n",
      "SF\n",
      "SA\n",
      "xGF\n",
      "xGA\n",
      "SCF\n",
      "SCA\n",
      "GF\n",
      "GA\n",
      "RBF\n",
      "RBA\n",
      "RSF\n",
      "RSA\n",
      "DSF\n",
      "DSA\n",
      "FOW\n",
      "FOL\n",
      "HF\n",
      "HA\n",
      "GVA\n",
      "TKA\n",
      "PENT\n",
      "PEND\n",
      "OPS\n",
      "DPS\n",
      "PS\n",
      "OTOI\n",
      "Grit\n",
      "DAP\n",
      "Pace\n",
      "GS\n",
      "GS/G\n",
      "AgeStart\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(r'C:\\Users\\Pat\\Documents\\Thinkful\\Files\\NHL salary test.csv', encoding = 'ISO-8859-1')\n",
    "train_df = pd.read_csv(r'C:\\Users\\Pat\\Documents\\Thinkful\\Files\\NHL salary train.csv', encoding = 'ISO-8859-1')\n",
    "salaries_df = pd.read_csv(r'C:\\Users\\Pat\\Documents\\Thinkful\\Files\\NHL salary test_salaries.csv', encoding = 'ISO-8859-1')\n",
    "\n",
    "# Statt of season is Oct 12, 2016\n",
    "def elapsed_days(start, end=datetime(2016,10,12)):\n",
    "\t\"\"\" calcualte the number of days start and end dates\"\"\"\n",
    "\tx = (end - start)\n",
    "\treturn x.days\n",
    "\n",
    "# Get ages for season\n",
    "train_df['AgeStart'] = train_df.apply(lambda x: \n",
    "    elapsed_days(datetime.strptime(x['Born'], '%y-%m-%d')) ,axis=1)\n",
    "\n",
    "test_df['AgeStart'] = test_df.apply(lambda x: \n",
    "    elapsed_days(datetime.strptime(x['Born'], '%y-%m-%d')) ,axis=1)\n",
    "\n",
    "train_df['AgeStart'] = train_df['AgeStart']/365.25\n",
    "test_df['AgeStart'] = test_df['AgeStart']/365.25\n",
    "\n",
    "\n",
    "\n",
    "# This player has a ton of missing info and only 1 game played\n",
    "# test_df = test_df[test_df['Last Name'] != 'Renouf']\n",
    "# train_df = test_df[test_df['Last Name'] != 'Renouf']\n",
    "\n",
    "# Drop columns that are of no use or redundant\n",
    "drop_cols = ['City', 'Pr/St', 'Cntry', 'Last Name', 'First Name', 'Team', 'Born']\n",
    "\n",
    "train_df.drop(drop_cols, axis = 1, inplace = True)\n",
    "test_df.drop(drop_cols, axis = 1, inplace = True)\n",
    "# Two average shot distance measures. Not sure what the difference is\n",
    "# but one is non-numeric and has missing values so I dropeed it\n",
    "test_df.drop('sDist.1', axis = 1, inplace = True)\n",
    "train_df.drop('sDist.1', axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "for i in test_df.columns.unique():\n",
    "    print(i)\n",
    "# print(test_df.columns.unique())\n",
    "# test_df['age_season_start']\n",
    "# test_df[['age_season_start', 'Born', 'Last Name', 'First Name']]\n",
    "\n",
    "train_df = train_df.dropna()\n",
    "\n",
    "# train_df = train_df.reset_index()\n",
    "# test_df = train_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns = train_df.columns.str.replace('/', '')\n",
    "train_df.columns = train_df.columns.str.replace('+', 'pls')\n",
    "train_df.columns = train_df.columns.str.replace('-', 'min')\n",
    "train_df.columns = train_df.columns.str.replace('%', 'perc')\n",
    "train_df.columns = train_df.columns.str.replace('.', '')\n",
    "train_df.columns = train_df.columns.str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>AgeStart</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>iSF</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>iTKA</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>iGVA</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>iMiss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>iHDf</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>iHA</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>iHF1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>iHF</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Pass</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sDist</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>iDS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>iRS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>iRB</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>iSCF</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Total  Percent\n",
       "AgeStart      0      0.0\n",
       "iSF           0      0.0\n",
       "iTKA          0      0.0\n",
       "iGVA          0      0.0\n",
       "iMiss         0      0.0\n",
       "iHDf          0      0.0\n",
       "iHA           0      0.0\n",
       "iHF1          0      0.0\n",
       "iHF           0      0.0\n",
       "Pass          0      0.0\n",
       "sDist         0      0.0\n",
       "iDS           0      0.0\n",
       "iRS           0      0.0\n",
       "iRB           0      0.0\n",
       "iSCF          0      0.0"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing values\n",
    "total_missing = train_df.isnull().sum().sort_values(ascending=False)\n",
    "percent_missing = (train_df.isnull().sum()/train_df.isnull().count()).sort_values(ascending=False)\n",
    "# missing_data = pd.concat([total_missing, percent_missing], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data = pd.concat([total_missing, percent_missing], axis=1, keys=['Total', 'Percent'], sort=False)\n",
    "missing_data.head(15)\n",
    "\n",
    "# The top three columns are for undrafted players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat = ['Nat', 'Hand', 'Position']\n",
    "rem_feat = cat_feat\n",
    "rem_feat.append('Salary')\n",
    "# rem_feat\n",
    "num_feat = list(train_df.drop(cat_feat, axis=1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 train examples\n",
      "100 validation examples\n",
      "100 test examples\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(train_df, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.25)\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary</th>\n",
       "      <th>Nat</th>\n",
       "      <th>Ht</th>\n",
       "      <th>Wt</th>\n",
       "      <th>DftYr</th>\n",
       "      <th>DftRd</th>\n",
       "      <th>Ovrl</th>\n",
       "      <th>Hand</th>\n",
       "      <th>Position</th>\n",
       "      <th>GP</th>\n",
       "      <th>...</th>\n",
       "      <th>OPS</th>\n",
       "      <th>DPS</th>\n",
       "      <th>PS</th>\n",
       "      <th>OTOI</th>\n",
       "      <th>Grit</th>\n",
       "      <th>DAP</th>\n",
       "      <th>Pace</th>\n",
       "      <th>GS</th>\n",
       "      <th>GSG</th>\n",
       "      <th>AgeStart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>269</td>\n",
       "      <td>5800000</td>\n",
       "      <td>USA</td>\n",
       "      <td>77</td>\n",
       "      <td>225</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>R</td>\n",
       "      <td>RW</td>\n",
       "      <td>82</td>\n",
       "      <td>...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>8.2</td>\n",
       "      <td>3165.35</td>\n",
       "      <td>199</td>\n",
       "      <td>6.6</td>\n",
       "      <td>114.6</td>\n",
       "      <td>80.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>30.116359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>601</td>\n",
       "      <td>575000</td>\n",
       "      <td>FIN</td>\n",
       "      <td>71</td>\n",
       "      <td>203</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>L</td>\n",
       "      <td>RW</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>209.31</td>\n",
       "      <td>25</td>\n",
       "      <td>15.0</td>\n",
       "      <td>103.3</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>23.594798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>575000</td>\n",
       "      <td>USA</td>\n",
       "      <td>70</td>\n",
       "      <td>184</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>L</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>80.15</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.5</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>26.403833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>925000</td>\n",
       "      <td>RUS</td>\n",
       "      <td>73</td>\n",
       "      <td>201</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>L</td>\n",
       "      <td>D</td>\n",
       "      <td>82</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3080.32</td>\n",
       "      <td>311</td>\n",
       "      <td>8.9</td>\n",
       "      <td>107.3</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.43</td>\n",
       "      <td>19.745380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>309</td>\n",
       "      <td>1000000</td>\n",
       "      <td>FIN</td>\n",
       "      <td>73</td>\n",
       "      <td>193</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>L</td>\n",
       "      <td>LW/RW</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2895.21</td>\n",
       "      <td>83</td>\n",
       "      <td>9.8</td>\n",
       "      <td>117.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>30.209446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>394</td>\n",
       "      <td>575000</td>\n",
       "      <td>USA</td>\n",
       "      <td>73</td>\n",
       "      <td>198</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>L</td>\n",
       "      <td>C</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>245.70</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.06</td>\n",
       "      <td>28.049281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1650000</td>\n",
       "      <td>CAN</td>\n",
       "      <td>76</td>\n",
       "      <td>215</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>L</td>\n",
       "      <td>D</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1036.23</td>\n",
       "      <td>60</td>\n",
       "      <td>5.8</td>\n",
       "      <td>106.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>25.431896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>401</td>\n",
       "      <td>800000</td>\n",
       "      <td>CAN</td>\n",
       "      <td>77</td>\n",
       "      <td>236</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>R</td>\n",
       "      <td>D</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>241.92</td>\n",
       "      <td>35</td>\n",
       "      <td>8.0</td>\n",
       "      <td>95.5</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>24.479124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>667500</td>\n",
       "      <td>USA</td>\n",
       "      <td>72</td>\n",
       "      <td>193</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>R</td>\n",
       "      <td>RW</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123.26</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>22.677618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>4000000</td>\n",
       "      <td>CZE</td>\n",
       "      <td>72</td>\n",
       "      <td>204</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>R</td>\n",
       "      <td>D</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2523.16</td>\n",
       "      <td>500</td>\n",
       "      <td>10.3</td>\n",
       "      <td>113.0</td>\n",
       "      <td>36.7</td>\n",
       "      <td>0.55</td>\n",
       "      <td>26.354552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Salary  Nat  Ht   Wt   DftYr  DftRd   Ovrl Hand Position  GP  ...  OPS  \\\n",
       "269  5800000  USA  77  225  2004.0    1.0    5.0    R       RW  82  ...  6.5   \n",
       "601   575000  FIN  71  203  2011.0    2.0   52.0    L       RW   5  ... -0.2   \n",
       "158   575000  USA  70  184  2008.0    2.0   40.0    L        D   2  ...  0.0   \n",
       "48    925000  RUS  73  201  2015.0    1.0    7.0    L        D  82  ...  1.7   \n",
       "309  1000000  FIN  73  193  2004.0    1.0   19.0    L    LW/RW  69  ...  0.7   \n",
       "..       ...  ...  ..  ...     ...    ...    ...  ...      ...  ..  ...  ...   \n",
       "394   575000  USA  73  198  2007.0    5.0  135.0    L        C   6  ... -0.2   \n",
       "320  1650000  CAN  76  215  2009.0    2.0   54.0    L        D  27  ... -0.3   \n",
       "401   800000  CAN  77  236  2010.0    1.0   10.0    R        D   6  ...  0.1   \n",
       "76    667500  USA  72  193  2012.0    6.0  167.0    R       RW   3  ... -0.1   \n",
       "34   4000000  CZE  72  204  2010.0    3.0   66.0    R        D  67  ...  1.6   \n",
       "\n",
       "     DPS   PS     OTOI  Grit   DAP   Pace    GS   GSG   AgeStart  \n",
       "269  1.7  8.2  3165.35   199   6.6  114.6  80.6  1.00  30.116359  \n",
       "601  0.0 -0.1   209.31    25  15.0  103.3  -0.6 -0.13  23.594798  \n",
       "158  0.0 -0.1    80.15     4   0.0   93.5  -0.6 -0.28  26.403833  \n",
       "48   3.9  5.7  3080.32   311   8.9  107.3  35.3  0.43  19.745380  \n",
       "309  1.0  1.8  2895.21    83   9.8  117.3  18.0  0.26  30.209446  \n",
       "..   ...  ...      ...   ...   ...    ...   ...   ...        ...  \n",
       "394  0.0 -0.2   245.70     6   0.0  105.0   0.4  0.06  28.049281  \n",
       "320  0.5  0.2  1036.23    60   5.8  106.0   1.4  0.05  25.431896  \n",
       "401  0.0  0.1   241.92    35   8.0   95.5  -0.3 -0.05  24.479124  \n",
       "76   0.0  0.0   123.26     1   0.0  102.5  -0.4 -0.12  22.677618  \n",
       "34   3.9  5.5  2523.16   500  10.3  113.0  36.7  0.55  26.354552  \n",
       "\n",
       "[300 rows x 147 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  dataframe = dataframe.copy()\n",
    "  labels = dataframe.pop('Salary')\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ({Nat: (None,), Ht: (None,), Wt: (None,), DftYr: (None,), DftRd: (None,), Ovrl: (None,), Hand: (None,), Position: (None,), GP: (None,), G: (None,), A: (None,), A1: (None,), A2: (None,), PTS: (None,), plsmin: (None,), Eplsmin: (None,), PIM: (None,), Shifts: (None,), TOI: (None,), TOIX: (None,), TOIGP: (None,), TOIGP1: (None,), TOIperc: (None,), IPPperc: (None,), SHperc: (None,), SVperc: (None,), PDO: (None,), F60: (None,), A60: (None,), Pctperc: (None,), Diff: (None,), Diff60: (None,), iCF: (None,), iCF1: (None,), iFF: (None,), iSF: (None,), iSF1: (None,), iSF2: (None,), ixG: (None,), iSCF: (None,), iRB: (None,), iRS: (None,), iDS: (None,), sDist: (None,), Pass: (None,), iHF: (None,), iHF1: (None,), iHA: (None,), iHDf: (None,), iMiss: (None,), iGVA: (None,), iTKA: (None,), iBLK: (None,), iGVA1: (None,), iTKA1: (None,), iBLK1: (None,), BLKperc: (None,), iFOW: (None,), iFOL: (None,), iFOW1: (None,), iFOL1: (None,), FOperc: (None,), percFOT: (None,), dzFOW: (None,), dzFOL: (None,), nzFOW: (None,), nzFOL: (None,), ozFOW: (None,), ozFOL: (None,), FOWUp: (None,), FOLUp: (None,), FOWDown: (None,), FOLDown: (None,), FOWClose: (None,), FOLClose: (None,), OTG: (None,), 1G: (None,), GWG: (None,), ENG: (None,), PSG: (None,), PSA: (None,), GBkhd: (None,), GDflct: (None,), GSlap: (None,), GSnap: (None,), GTip: (None,), GWrap: (None,), GWrst: (None,), CBar: (None,), Post: (None,), Over: (None,), Wide: (None,), SBkhd: (None,), SDflct: (None,), SSlap: (None,), SSnap: (None,), STip: (None,), SWrap: (None,), SWrst: (None,), iPenT: (None,), iPenD: (None,), iPENT: (None,), iPEND: (None,), iPenDf: (None,), NPD: (None,), Min: (None,), Maj: (None,), Match: (None,), Misc: (None,), Game: (None,), CF: (None,), CA: (None,), FF: (None,), FA: (None,), SF: (None,), SA: (None,), xGF: (None,), xGA: (None,), SCF: (None,), SCA: (None,), GF: (None,), GA: (None,), RBF: (None,), RBA: (None,), RSF: (None,), RSA: (None,), DSF: (None,), DSA: (None,), FOW: (None,), FOL: (None,), HF: (None,), HA: (None,), GVA: (None,), TKA: (None,), PENT: (None,), PEND: (None,), OPS: (None,), DPS: (None,), PS: (None,), OTOI: (None,), Grit: (None,), DAP: (None,), Pace: (None,), GS: (None,), GSG: (None,), AgeStart: (None,)}, (None,)), types: ({Nat: tf.string, Ht: tf.int32, Wt: tf.int32, DftYr: tf.float32, DftRd: tf.float32, Ovrl: tf.float32, Hand: tf.string, Position: tf.string, GP: tf.int32, G: tf.int32, A: tf.int32, A1: tf.int32, A2: tf.int32, PTS: tf.int32, plsmin: tf.int32, Eplsmin: tf.float32, PIM: tf.int32, Shifts: tf.int32, TOI: tf.int32, TOIX: tf.float32, TOIGP: tf.float32, TOIGP1: tf.float32, TOIperc: tf.float32, IPPperc: tf.float32, SHperc: tf.float32, SVperc: tf.float32, PDO: tf.float32, F60: tf.float32, A60: tf.float32, Pctperc: tf.float32, Diff: tf.int32, Diff60: tf.float32, iCF: tf.float32, iCF1: tf.int32, iFF: tf.float32, iSF: tf.float32, iSF1: tf.int32, iSF2: tf.int32, ixG: tf.float32, iSCF: tf.float32, iRB: tf.float32, iRS: tf.float32, iDS: tf.float32, sDist: tf.float32, Pass: tf.float32, iHF: tf.int32, iHF1: tf.float32, iHA: tf.float32, iHDf: tf.float32, iMiss: tf.int32, iGVA: tf.int32, iTKA: tf.int32, iBLK: tf.int32, iGVA1: tf.float32, iTKA1: tf.float32, iBLK1: tf.float32, BLKperc: tf.float32, iFOW: tf.int32, iFOL: tf.int32, iFOW1: tf.float32, iFOL1: tf.float32, FOperc: tf.float32, percFOT: tf.float32, dzFOW: tf.int32, dzFOL: tf.int32, nzFOW: tf.int32, nzFOL: tf.int32, ozFOW: tf.int32, ozFOL: tf.int32, FOWUp: tf.int32, FOLUp: tf.int32, FOWDown: tf.int32, FOLDown: tf.int32, FOWClose: tf.int32, FOLClose: tf.int32, OTG: tf.int32, 1G: tf.int32, GWG: tf.int32, ENG: tf.int32, PSG: tf.int32, PSA: tf.int32, GBkhd: tf.int32, GDflct: tf.int32, GSlap: tf.int32, GSnap: tf.int32, GTip: tf.int32, GWrap: tf.int32, GWrst: tf.int32, CBar: tf.int32, Post: tf.int32, Over: tf.int32, Wide: tf.int32, SBkhd: tf.int32, SDflct: tf.int32, SSlap: tf.int32, SSnap: tf.int32, STip: tf.int32, SWrap: tf.int32, SWrst: tf.int32, iPenT: tf.int32, iPenD: tf.int32, iPENT: tf.float32, iPEND: tf.float32, iPenDf: tf.int32, NPD: tf.float32, Min: tf.int32, Maj: tf.int32, Match: tf.int32, Misc: tf.int32, Game: tf.int32, CF: tf.float32, CA: tf.float32, FF: tf.float32, FA: tf.float32, SF: tf.float32, SA: tf.float32, xGF: tf.float32, xGA: tf.float32, SCF: tf.float32, SCA: tf.float32, GF: tf.float32, GA: tf.float32, RBF: tf.float32, RBA: tf.float32, RSF: tf.float32, RSA: tf.float32, DSF: tf.int32, DSA: tf.int32, FOW: tf.float32, FOL: tf.float32, HF: tf.float32, HA: tf.float32, GVA: tf.float32, TKA: tf.float32, PENT: tf.float32, PEND: tf.float32, OPS: tf.float32, DPS: tf.float32, PS: tf.float32, OTOI: tf.float32, Grit: tf.int32, DAP: tf.float32, Pace: tf.float32, GS: tf.float32, GSG: tf.float32, AgeStart: tf.float32}, tf.int32)>"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scal(feature):\n",
    "  def minmax(x):\n",
    "    mini = train[feature].min()\n",
    "    maxi = train[feature].max()\n",
    "    return (x - mini)/(maxi-mini)\n",
    "  return(minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every feature: ['Nat', 'Ht', 'Wt', 'DftYr', 'DftRd', 'Ovrl', 'Hand', 'Position', 'GP', 'G', 'A', 'A1', 'A2', 'PTS', 'plsmin', 'Eplsmin', 'PIM', 'Shifts', 'TOI', 'TOIX', 'TOIGP', 'TOIGP1', 'TOIperc', 'IPPperc', 'SHperc', 'SVperc', 'PDO', 'F60', 'A60', 'Pctperc', 'Diff', 'Diff60', 'iCF', 'iCF1', 'iFF', 'iSF', 'iSF1', 'iSF2', 'ixG', 'iSCF', 'iRB', 'iRS', 'iDS', 'sDist', 'Pass', 'iHF', 'iHF1', 'iHA', 'iHDf', 'iMiss', 'iGVA', 'iTKA', 'iBLK', 'iGVA1', 'iTKA1', 'iBLK1', 'BLKperc', 'iFOW', 'iFOL', 'iFOW1', 'iFOL1', 'FOperc', 'percFOT', 'dzFOW', 'dzFOL', 'nzFOW', 'nzFOL', 'ozFOW', 'ozFOL', 'FOWUp', 'FOLUp', 'FOWDown', 'FOLDown', 'FOWClose', 'FOLClose', 'OTG', '1G', 'GWG', 'ENG', 'PSG', 'PSA', 'GBkhd', 'GDflct', 'GSlap', 'GSnap', 'GTip', 'GWrap', 'GWrst', 'CBar', 'Post', 'Over', 'Wide', 'SBkhd', 'SDflct', 'SSlap', 'SSnap', 'STip', 'SWrap', 'SWrst', 'iPenT', 'iPenD', 'iPENT', 'iPEND', 'iPenDf', 'NPD', 'Min', 'Maj', 'Match', 'Misc', 'Game', 'CF', 'CA', 'FF', 'FA', 'SF', 'SA', 'xGF', 'xGA', 'SCF', 'SCA', 'GF', 'GA', 'RBF', 'RBA', 'RSF', 'RSA', 'DSF', 'DSA', 'FOW', 'FOL', 'HF', 'HA', 'GVA', 'TKA', 'PENT', 'PEND', 'OPS', 'DPS', 'PS', 'OTOI', 'Grit', 'DAP', 'Pace', 'GS', 'GSG', 'AgeStart']\n",
      "A batch of heights: tf.Tensor(\n",
      "[ 1 12  0  6 13  4  6 11  1 33 14 25  5  0  6 11  5  3  6  0 17 36  2  1\n",
      "  6 23  0  0  1 23 21  2], shape=(32,), dtype=int32)\n",
      "A batch of targets: tf.Tensor(\n",
      "[  800000   832500  2000000  4250000  4500000  2250000  3667000  2500000\n",
      "  3250000 10000000  2950000  2750000  4500000   925000  3000000   925000\n",
      "  2900000   600000   667500   575000  5000000   925000   575000   792500\n",
      "   715000  7000000   700000   575000   950000  3750000  4500000   800000], shape=(32,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for feature_batch, label_batch in train_ds.take(1):\n",
    "  print('Every feature:', list(feature_batch.keys()))\n",
    "  print('A batch of heights:', feature_batch['G'])\n",
    "  print('A batch of targets:', label_batch )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "for header in num_feat:\n",
    "  scal_input_fn = get_scal(header)\n",
    "  feature_columns.append(feature_column.numeric_column(header, normalizer_fn=scal_input_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature_name in cat_feat:\n",
    "  vocabulary = train_df[feature_name].unique()\n",
    "  cat_c = tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary)\n",
    "  one_hot = feature_column.indicator_column(cat_c)\n",
    "  feature_columns.append(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NumericColumn(key='Ht', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function get_scal.<locals>.minmax at 0x000002491CAF3E18>)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in converted code:\n    relative to C:\\Users\\Pat\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\feature_column:\n\n    dense_features.py:133 call\n        self._state_manager)\n    feature_column_v2.py:4360 get_dense_tensor\n        return transformation_cache.get(self, state_manager)\n    feature_column_v2.py:2608 get\n        transformed = column.transform_feature(self, state_manager)\n    feature_column_v2.py:4299 transform_feature\n        transformation_cache, state_manager)\n    feature_column_v2.py:3774 get_sparse_tensors\n        transformation_cache.get(self, state_manager), None)\n    feature_column_v2.py:2608 get\n        transformed = column.transform_feature(self, state_manager)\n    feature_column_v2.py:3751 transform_feature\n        transformation_cache.get(self.key, state_manager))\n    feature_column_v2.py:2600 get\n        raise ValueError('Feature {} is not in features dictionary.'.format(key))\n\n    ValueError: Feature Salary is not in features dictionary.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-233-4abb750fb996>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m model_fit = model.fit(train_ds,\n\u001b[0;32m     16\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m           epochs=10)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m           distribution_strategy=strategy)\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    548\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m         steps=steps)\n\u001b[0m\u001b[0;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[0;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2417\u001b[0m     \u001b[1;31m# First, we build the model on the fly if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2419\u001b[1;33m       \u001b[0mall_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_model_with_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2420\u001b[0m       \u001b[0mis_build_called\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2421\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_build_model_with_inputs\u001b[1;34m(self, inputs, targets)\u001b[0m\n\u001b[0;32m   2620\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2621\u001b[0m       \u001b[0mcast_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2622\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2623\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mprocessed_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_dict_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_set_inputs\u001b[1;34m(self, inputs, outputs, training)\u001b[0m\n\u001b[0;32m   2707\u001b[0m           \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'training'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2708\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2709\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2710\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2711\u001b[0m         \u001b[1;31m# This Model or a submodel is dynamic and hasn't overridden\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    840\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[0;32m    841\u001b[0m                   \u001b[1;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 842\u001b[1;33m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    843\u001b[0m                     \u001b[1;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m                     \u001b[1;31m# circular dependencies.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'training'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m       \u001b[1;31m# `outputs` will be the inputs to the next layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    840\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[0;32m    841\u001b[0m                   \u001b[1;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 842\u001b[1;33m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    843\u001b[0m                     \u001b[1;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m                     \u001b[1;31m# circular dependencies.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    235\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in converted code:\n    relative to C:\\Users\\Pat\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\feature_column:\n\n    dense_features.py:133 call\n        self._state_manager)\n    feature_column_v2.py:4360 get_dense_tensor\n        return transformation_cache.get(self, state_manager)\n    feature_column_v2.py:2608 get\n        transformed = column.transform_feature(self, state_manager)\n    feature_column_v2.py:4299 transform_feature\n        transformation_cache, state_manager)\n    feature_column_v2.py:3774 get_sparse_tensors\n        transformation_cache.get(self, state_manager), None)\n    feature_column_v2.py:2608 get\n        transformed = column.transform_feature(self, state_manager)\n    feature_column_v2.py:3751 transform_feature\n        transformation_cache.get(self.key, state_manager))\n    feature_column_v2.py:2600 get\n        raise ValueError('Feature {} is not in features dictionary.'.format(key))\n\n    ValueError: Feature Salary is not in features dictionary.\n"
     ]
    }
   ],
   "source": [
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  feature_layer,\n",
    "  layers.Dense(16, kernel_regularizer=tf.keras.regularizers.l2(0.01), activation='relu'),\n",
    "  layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l2(0.01), activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  \n",
    "  layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_fit = model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
